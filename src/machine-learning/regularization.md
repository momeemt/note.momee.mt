# 正則化

## 動機

複雑度の高いモデルは、訓練誤差は抑えられるがテスト誤差は大きくなる。
そこで、モデルに対する知識で複雑さを制御することでテスト誤差を制御する**正則化**を導入する。

## 罰則付き最適化

両者が矛盾するような $f(\boldsymbol{x}), g(\boldsymbol{x})$ の両方を最小化するような問題を考える。

$$
\text{minimize} h(\boldsymbol{x}) = f(\boldsymbol{x}) + \lambda g(\boldsymbol{x})
$$

回帰問題に対しては、訓練誤差の最小化と複雑さの最小化をトレードオフパラメータ$\lambda$によって制御して、汎化誤差が小さくなることを期待する。

